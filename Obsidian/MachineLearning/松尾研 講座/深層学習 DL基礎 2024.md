### 目次
[[#第2回 機械学習基礎]]
[[#第3回 ニューラルネットワーク基礎]]
[[#第4回 ニューラルネットワークの最適化・正則化]]
[[#第5回 CNNと画像処理]]
[[#第6回 RNN]]
[[#第7回 自然言語処理]]
[[#第8回 説明可能性 及び グラフニューラルネットワーク]]
[[#第10回 深層学習の理論]]
[[#第12回 深層強化学習]]

--- 
### 第2回 機械学習基礎
- 機械学習の定義
	- 経験からの学習により性能を改善するプログラム
		- 経験：学習データ
		- 学習：より良いモデルに更新
		- 性能：予測と正解の誤差で評価
- 機械学習の分類
	- **教師あり
		- **分類**
			- **二値**
			- **多値**
		- **回帰**
	- 教師なし
		- 自己教師あり学習
	- 強化学習
		- モデルフリー
		- モデルベース
- 各分類の特徴
	- 教師あり学習
		- 入力$\boldsymbol{x}$と出力$y$の対応$y=f(\boldsymbol{x})$を推定
		- $\boldsymbol{x}:$ 説明変数, $y:$ 目的変数
		- 分類/回帰 は想定する出力値の 離散/連続 の違い
	- 教師なし学習
		- 入力データ集合$X$の構造を同定
	- 強化学習
		- 報酬を最大化する行動を選択するモデルを構築
- モデル
	- データセットのペアの関係を表す関数を探索する上で、
	  ありとあらゆる関数を考慮することは不可能
	- したがって、探索対象とする関数の空間をあらかじめ定める必要あり
		- パラメータで記述　(パラメトリックモデルと呼ぶ)
	- パラメータを調整するため、モデルの評価指標として目的関数が必要
		- 平均二乗誤差：回帰
		- クロスエントロピー誤差：分類
- 学習
	- 最尤推定
		- 尤度関数を最大化するパラメータの推定
		- 一例として、確率モデル$p_\theta(y|x)$の場合
			- 対数尤度 $log\ p_\theta(y|x)$
			- 訓練データ $\{(x_n,y_n)\}_{n=1}^N$ の場合の目的関数$$E(\theta)=-\sum_{n=1}^N log\ p_\theta(y_n|x_n)$$
			  を最小化
		- 目的関数は
			- $p_\theta(y|x)=$ (平均$f(x;\theta)$, 分散$I$のガウス分布) の場合
				- 平均二乗誤差に一致
			- $p_\theta(y|x)=$ (カテゴリカル分布)の場合
				- クロスエントロピー誤差と一致
			- ＊詳細は巻末補足資料
- 適切なモデル構造を決定
	- 訓練データで各モデルを学習
	- モデルの汎化性能を検証データで評価し、最良のモデルを選択
	- 最後にテストデータを使って最良モデルを評価
- モデル構造の決定方法
	- ホールドアウト検証
		- 単純
		- データセットを一定の割合で分割、一度のみ検証
	- k分割交差検証
		- データをk分割、それぞれを1度ずつ検証データとして学習・評価し、k回の評価の平均をモデルの性能と見なす
		- データセットが小さい場合に有効
- 次元の呪い
	- データの次元数増大に伴う難易度の指数関数的上昇
	- 解決策
		- 考慮する変数を厳選
		- 次元の圧縮
			- 主成分分析
---
### 第3回 ニューラルネットワーク基礎
- 多層パーセプトロン
	- ロジスティック回帰は線形分離しかできない
	- 非線形データを分離するには、入力空間を線形分離可能な空間に写像すればいい。これが、ニューラルネットワークの多層化で実現できる。
		- 隠れ層での変換がその写像に対応すると見なせる
	- ~層という表現は、レイヤーの数より変換の数とする方が最近主流
---
### 第4回 ニューラルネットワークの最適化・正則化

- 最適化
- 初期化
- 正則化
	- 過学習を抑制

#### 最適化アルゴリズム
SGD
- データ集合すべてを使って学習する**バッチ学習**ではなく、
  一部のバッチ、ミニバッチを毎回ランダムに選択し学習する**ミニバッチ学習**
	- データ集合からサンプルを確率的に選択し、誤差関数を求める
		- 局所解を防ぐ
- データ集合1周をエポック
- トレードオフ
	- 高速かつ局所解を避けたいなら学習率大きく
	- 学習率大きいと収束しない

普通のSGDも使われるが、
実際は収束が早くなるよう工夫された最適化手法が使われる

###### 更新量を決定する最適化アルゴリズム
- モメンタム(慣性項)
	- パラメータの更新量に、前の更新量を考慮する$$\Delta\theta^{(t)}=-\eta\nabla E(\theta^{(t-1)})\ +\ \boldsymbol{\gamma\Delta\theta^{(t-1)}}$$
	- 勾配の方向が変わる際に、行き過ぎないようにする
	- 逆に、同じ方向に進んでいるときは勢いづく
	- SGDの弱点である、収束速度と鞍点での振動 に効果
	- これを単純に使うものをMomentum SGDという（？）
- ネステロフの加速法
	- Momentum SGDを改良
	- 勾配の評価を現在のパラメータではなく、前回の更新量を使って大雑把に更新したパラメータで計算、今回の更新量を決定$$\Delta\theta^{(t)}=-\eta\nabla E(\theta^{(t-1)}\ +\ \boldsymbol{\gamma\Delta\theta^{(t-1)}})\ +\ \gamma\Delta\theta^{(t-1)}$$
	- 収束の高速化
	- scikit-learnでは標準でこれ

ここまではMomentumを使う手法
以降は、学習率を工夫する手法

- $AdaGrad$
	- 高次元のモデルでは、パラメータごとの勾配に大きな差が生じることがある
		- そのままでは更新量に大きな差が生まれる
		- これをならしてやる adaptive
	- 各次元(パラメータ)ごとに学習率を調整
		- 各次元の学習率を、その次元の過去の勾配の累積和で割る
			- それまで大きな勾配で学習 → 学習率を小さく
			- それまで小さな勾配で学習 → 学習率を大きく
		- $\Delta\theta^t_i=-\frac{\eta}{\sqrt{\sum^t_{j=0}{\nabla E(\theta^{(j)}_i)^2}}}\nabla E(\theta^{(t)}_i)$
- $RMSprop$
	- AdaGradを改良
		- デメリット：一度学習率が0に近づくと上がれない
		- 重みをかけて直近の勾配の累積和をより重視しよう
	- $g^{(t)}_i=\nabla E(\theta^{(t)}_i)$として$$\Delta\theta^{(t)}_i=-\frac{\eta}{\sqrt{v^{(t)}_i\ +\ \epsilon}}g^{(t)}_i,\ v^{(t)}_i=\rho v^{(t-1)}_i\ +\ (1-\rho)(g^{(t)}_i)^2\ \ \ \ \ \ \ \ (v_0=0)$$
	  以前の勾配は$\rho$により減衰する

Momentum + 学習率の調整

- $Adam$
	- Momentum + RMSprop

結局どれを使えばいいのか
→ Adamが主流

#### パラメータ初期化
- 素朴な方法：ランダムな初期化
	- 勾配消失のリスク
		- 活性化関数の勾配の小さい領域に入ってしまう
		- 深いと活性化関数を何度もかけるため顕著
- 事前学習
	- 相互との事前学習
	- 今はもう使わん
- Xavier法 / Glorot法
	- 初期重みを、層の大きさに応じた分散を持つ一様分布からサンプリング
	- 活性化関数としてtanhを想定
- He法
	- Xavierを改良
	- 活性化関数としてReLUを想定

#### 正規化
正規化(Normalization)の目的
- 内部共変量シフトの抑制
	- 中間表現やその分布は、学習の過程で変化していく(当然)
	- 分布の平均や分散を一定にしておくことで、学習がうまくいくように

###### 様々な正規化：どの軸に沿って正規化するか
- Batch Normalization
	- ニューラルネットの中間表現を正規化
	-  バッチごとに平均と分散を求めて正規化
- Layer Normalization
	- 特徴量(チャンネル)方向に正規化
	- Batch Normalizationの問題
		- データ方向に正規化するので、バッチサイズが小さいと不安定に
		- RNNへの適用がムズイ。文章などのシークエンスの長さがサンプルごとに異なる
	- LLM等でも
- Instance Normalization
	- Layerの亜種的な
- Group Normalization
	- チャンネルをグループ分け、各グループ内で正規化

#### 正則化
過学習をどう防ぐか
- L2正則化
	- 目的関数に重みのL2ノルムを入れる
	- 直感的に言えば重みが大きくなりすぎるのを防ぐ
	- 重みが大きくなる過ぎると過学習に(過剰適合)
	- この手法は一般に重み減衰(werght decay)として知られ、重みを原点に近づける
	- ライブラリのoptimizerに対して指定できる
	- 重み減衰項を追加することで、ステップごとに一定の割合で重みベクトルが減少
- L1正則化
	- 目的はL2と同じ、重みの増大を抑える
	- L2と比べ、よりスパースな解が得られやすい。すなわち、パラメータの最適地が0になりやすい/近づきやすい
		- このスパース性が、特徴量選択のメカニズムに使用される
- Data Augmentation
	- 「猫は左右反転しても猫のまま」等の人間の知識を
	  モデルに与えることによる正則化とも解釈できる
	- データも水増しできる
	- データによっては不適切なデータ拡張方法が存在
		- MNISTへの回転
		- 文字の一部切り取り　
- ラベル平滑化：ノイズへの頑健性
	- ラベルyに間違いが含まれるとき、ラベルに生じうるノイズをモデル化することが有効な場合がある
		- ラベルが一定の確率$\epsilon$で間違っているという仮定を解析的にコスト関数に組み込む = **ラベル平滑化**
		- ラベル平滑化では、kクラスラベルのone-hotベクトルの0/1を、$\frac{\epsilon}{k-1}$ / $1-\epsilon$に置き換えることでモデルを正則化 (← soft target ( ? ))
			- hard target: {0, 1, 0, 0}
			- soft target: {0.1, 0.7, 0.1, 0.1}
		- softmaxとhard targetによる最尤推定は収束しない場合が存在
			- softmaxは0/1ちょうどの値を出力できないので、重みが増大し続ける
			- weight decay等ほかの正則化手法での解決も可能
- マルチタスク学習
	- 複数のタスクを同時に学習させることで一つの問題への過学習を防ごう
- 早期終了
- アンサンブル学習
	- DLでは正直あんま使わん
	- 複数の学習器を組み合わせて訓練、汎化性能を向上
	- 個々の学習器はベース学習器、弱学習器と呼ばれる
	- 代表的な手法
		- ブースティング
		- バギング
		- スタッキング
	- なぜ汎化性能が向上するか
		- スライドp44
- Dropout
	- DLで疑似的にアンサンブル学習
	- 学習時
		- 順伝搬：バッチごとにユニット(ノード?)を確率的にマスク
		- 逆伝搬：選ばれたサブネットワーク上で逆伝搬
	- 推論時
		- 全ユニットを使用するが、出力スケールを選択確率に基づき合わせる
			- 消去されなかった確率をかける
	- 巨大NNの過学習を抑制
	- ノードか重みか
		- ドロップアウト：ノードの出力を確率的に0にマスク
		- ドロップコネクト：重みを確率的に0にマスク。
	- なぜ汎化性能が向上？
		- 同時に複数モデルを学習し平均をとっていることに相当するため、多様性に富むモデルとなる

#### 実践的な方法論

- 教師ナシ学習
		  データの特徴や構造を学習
	- クラスタリング
		- K-means法, DBSCAN
	- 次元削減
		- 主成分分析, オートエンコーダ
- 半教師あり学習
	- 学習データに**ラベルあり**と**ラベルなし**が混在
- 転移学習
	- 「新規タスクの効果的な仮説を効率的に見つけ出すため、一つ以上のタスクで学習された知識を得て、それを適用する問題」
	- Fine-tuning: 事前学習 → 再訓練
		- データ分布が離れているとうまくいかない
	- 学習データとテストデータの分布が一致しない状況はドメインシフトと呼ばれ、それに対処する手法が盛んに研究
		- DAN: Domain Adversarial Net
		- CrossGrad


ハイパーパラメータの実験管理
- .yamlファイルでハイパラを一括管理 Hydraなどのツール
- Tensorboard, W&Bなどを使い実験を可視化・管理
- 探索手法
	- グリッドサーチ
		- あらかじめ指定した組み合わせをすべて試す
		- 長所：網羅的に探索するため、最適な組み合わせが確実に見つかる
		- 短所：時間コスト
	- ランダムサーチ
		- 指定回数だけ組み合わせの中からランダムに探索
		- 長所：探索時間の削減
		- 短所：最適な組み合わせが見つかる確率減
	- 探索には必ず検証データを使用

Neural Architecture Search (NAS)　[Tan+ 2019]
- ネットワークアーキテクチャを半自動で決定
- AutoMLとも
- パラメータを出力するネットワークを用意して、そのネットワークも学習

---
### 第5回 CNNと画像処理
畳み込み処理の利点
- 画像の局所的な結合を利用
- パラメータ少ない
- 等価性
	- $f(g(x))=g(f(x))$ のとき、$f$と$g$は等価であるという
	- 「畳み込み と 平行移動 は等価」 = 「物体等が画像中のどこにあっても、同じ特徴が発現」

パディング
- ゼロパディング
- sameパディング
	- 入出力サイズを同じに保つのに最低限のゼロパディング
- リフレクトパディング
	- パディングの値として入力の端の値を採用
- リピートパディング
	- 入力データの端の値をそのまま繰り返す。

プーリングの利点
- 計算効率
- 移動不変性
	- 入力の平行移動に対して出力がある程度変わらない = 頑健性
- 可変長入力
	- 畳み込みやプーリングは入力サイズに依らず適用可能

入力画像の前処理
- 平均や分散を合わせたい
- 手法
	- ZCA白色化
		- PCAで白色化(無相関化＋分散正規化)したあと、元の空間に戻す
	- Global contrast normalization
	- 平均分散正規化

なぜ3x3convなのか
- 受容野：ある出力がどの程度の入力に影響されるか
	- 同じ受容野でも、1回の大きなカーネルでやるより、3x3を重ねた方がパラメータ数が少なく済み、なおかつより非線形

Residual Connection (Skip Connection)
勾配消失を低減

Bottleneck Block
- 1x1, 3x3, 1x1の順で畳み込むことで、ネットワークの深さを増やしつつ、パラメータ数と計算量を削減
---
### 第6回 RNN
	回帰結合型ニューラルネットワーク
#### 系列データ
- 定義
	- 系列性を持つデータ
	- 自然言語、音声、経済統計等
	- 系列性：過去の状態が現在の状態を左右
- 目的
	- 未来の予測
- 深層学習の研究
	- 機械翻訳, 音声認識, ...
	- CNNも活用
###### 系列予測
- データの順序に意味がある
	- 並び順により入力の意味が異なることを伝える必要
- 入力したい系列の長さはまちまち
	- 長さに対して汎化したい
	- 出力したい長さも変化
###### 系列予測の準備・工夫
- 入力
	- 系列データ $x(t)=x_1, x_2, x_3, ..., x_T$
- 時刻$t$
	- 通常のNNでは時刻$t$の情報がネットワーク内に保持されない
	- 現在時刻$t$の情報と$t$までの過去情報の両方が必要
	- これらの情報を隠れ層hに保持したい
		- 時刻により隠れ層の状態も変化するため、
		  時刻$t$における状態を$h(t)$と表記する
#### 基本的なRNN
系列データを処理するNNの一種
- 過去の隠れ層の状態を考慮しながら学習が進む
	- 過去のパラメータの共有、とも換言
- 過去の状態を再帰的にフィードバック
	- 過去の隠れ層の状態を現在の隠れ層に反映
###### BPTT: 通時的誤差逆伝搬法
過去にも誤差伝搬が起こる
**ここは一旦飛ばす**
###### Sequence-to-sequence モデル
#### LSTM: 長・短期記憶
###### 亜種: GRU(ゲート付き再帰的ユニット)
勾配の消失をなくしたい
###### 勾配クリッピング
勾配爆発をなくしたい
#### Attention mechanism
---
### 第7回 自然言語処理
##### 目標
- NLPの概要
- 深層学習によるNLP
	- Word Embedding
	- Encoder-Decoder
	- Attention
- 深層学習によるNLPの課題と研究動向

###### 自然言語の記号としてどう特徴的か
- 生産性
	- 新たな単語が増える
- 構成性
	- 文の意味が、文の構成要素と構造から決定
	- 同じ組み合わせでも、主語と目的語が入れ替われば文の意味は一変
- 文脈
	- 前後の表現で意味が定まる

###### 深層学習の登場
- 以前
	- 部分問題ごとにモデルを構築・学習
- 以後
	- 部分問題の学習を隠れ層での学習に置き換え
	- end-to-endでの学習が可能に
	- 反面、出力までの思考の過程がblack-box

#### 深層学習による自然言語処理
##### (1) 単語のベクトル表現
- 埋め込みによる表現
	- 共起行列
		- **分布仮説**：単語の意味はその周囲の単語から形成
		- 共起：単語Aと単語Bは同時に出現しやすい
		- 単語の意味を、周囲の単語との共起頻度で表現できないか
		- 他の単語との共起頻度を表したのが共起行列
		- 例：周囲1単語を文脈とした場合の、4単語からなる文章の共起行列$$\begin{bmatrix} 0 & 1 & 0 & 0 \\ 1 & 0 & 1 & 0 \\0 & 1 & 0 & 1 \\0 & 0 & 1 & 0 \\ \end{bmatrix}$$
		  縦横いずれのindexも各単語が対応
	- one-hotベクトル
		- indexごとに1つ単語が対応
		- 次元がでかいかつほとんど0(スパース)で計算量無駄
		- 単語埋め込みベクトル(分散表現)の学習により、低次元で密なベクトルへ

###### 単語の分散表現
$$h=Wx$$
$x:$ one-hotベクトル
$h:$ 密なベクトル
$W:$ 埋め込み行列. この$i$列目は単語$i$の埋め込みベクトル

###### Word2Vec [Micolov+, 2013]
分布仮説を、周囲の単語から間の単語を推測する問題に帰着させた言語モデル
- 言語モデル：単語列$w_0, w_1, ..., w_{i-1}$から、それに続く単語$w_i$の出現確率$P(w_0, w_1, ..., w_i)$を計算するモデル
- Word2Vec
	- 分布仮説に基づき、埋め込み行列Wを学習する言語モデル![[DL基礎_Word2Vecのアーキテクチャ.png]]
	  左：CBOW. 周辺から中心を予測
	  右：Skip-Gramモデル. 中心から周辺を予測
	  詳細はスライド
	- 問題点 -分布仮説に起因する問題-
		- 反義語は共起する単語が似る
			- 合格/不合格
		- 多義語は文脈に応じ語義曖昧性を解消する必要あり
			- Word2Vecは単語にベクトルをstaticに割り当てるため問題

###### ELMo
Word2Vecの問題点であるstatic性を解消
文脈から単語埋め込みベクトルを獲得 [Peters+, 2018]
"文脈化単語埋め込みベクトル"

###### 加法構成性
- 単語埋め込みベクトルの利点は低次元化による計算効率向上だけではない
- ベクトルの加減算が、単語の意味の加減算となる
	- king - man + woman = queen
- では、単語埋め込みベクトルをうまく合成して、
  文の意味を表現できるのでは？
  => Encoder-Decoderモデル

##### (2) 系列変換による文の意味表現
Encoder-Decoderモデル
![[DL基礎_Encoder-Decoderモデル.png]]
Encoder: 系列Xを、固定長ベクトルZに変換するモデル
Decoder: 固定長ベクトルZから系列Yを出力するモデル

###### 文の意味表現：RNNとCNN
- RNN: 系列の位置情報が捉えられるが並列性に難
- CNN: 局所的な位置情報を掴み高速だが大局的な位置情報は失われる

双方の長所を両立したのがAttention
- 系列中の重要な情報(文中のある単語の意味を理解するのにどの単語に注目すべきか)を直接用いる機構
- 系列の位置情報を活用しつつ、並列しやすい
- AttentionつきEncoder-Decoderモデル
	1. 各位置のEncoderの隠れ層のベクトルと、位置jのDecoderの隠れ層のベクトル間の類似度を計算. このときsoftmaxで正規化
	2. 類似度を使い、Encoderの隠れ層ベクトルの加重平均をとる. 
		- 位置jでの変換に必要な文脈情報を抽出している(Soft attention)
	1.  最終的な位置jのDecoderの隠れ層のベクトルを計算
	- 詳細はP47~

###### Transformer
- RNNやCNNを用いず、Attentionのみを用いたEncoder-Decoderモデル
- N(=6が多い)層のEncoder/Decoder
- Encoder 1層につき
	- Self Attention
	- Multi-head Attention
	- Layer Normalization
	- Feed-forward Layer
- 語の位置情報：Positional Encoding
- それまでのAttentionとちがい、Encoder/Decoder両方に使えるAttentionがSelf Attention
- Multi-head Attention:様々な側面から見た各単語の潜在表現を得られる
- Self Attentionでは位置情報が考慮できない→Position Embedding
##### 3. 大規模言語モデル
GPT(Generative Pre-trained Transformer)
- 片方向で逆方向(後ろ)の情報を考慮できないことが課題

BERT(Bidirectional Encoder Representations from Transformers) 2019
- 双方向Transformer
	- 事前学習とFine-tuningにより多様なタスクに対応
	- 2つの事前学習タスク
		- Masked Language Model
			- 入力データの一部をマスキング、それを予測する
		- Next Sentence Prediction
			- 文のペアが与えられ、一方がもう一方のあとに続くかを予測
		- いずれも、人手の正解データを必要としない自己教師あり学習

GPT-3 2020

---
### 第8回 説明可能性 及び グラフニューラルネットワーク
---
### 第10回 深層学習の理論
学んだこと
- 深層学習の性能の原理は未解明
	- 過去の技術も未解明のまま発展し、あとから理論が確立されてきた
	- いずれは深層学習の研究をもとにした新たな数学や理論が生まれるであろう
- ニューラルネットとは
	- 経験誤差を最小化し、汎化誤差を評価
- ニューラルネットの層の数や幅が誤差に与える影響を理論的に分析するため、汎化誤差を3つに分解
	- ![[DL基礎_汎化誤差の分解.png]]
	- ![[DL基礎_汎化誤差の分解を使い.png]]
- 近似誤差
	- 普遍近似定理
		- ![[DL基礎_普遍近似定理.png]]
		- [よく知られている結果]
		  層が2つのNNでは、
		  十分な数のパラメータがあれば、
		  連続関数を任意の精度で近似可能
		- **ではなぜDNNを使うのか**
	- 近似誤差の減衰レート
		- パラメータ数を増やした場合に、どれぐらい早く近似誤差が改善するか
		- ![[DL基礎_近似誤差の減衰レート.png]]
		- DNNは理論的に最適な誤差レート
			- でもフーリエ基底をはじめ他の近似手法でもそのレートを達成
			- **ではなぜDNNを使うのか**
	- DNNが優位な状況の発見
		- ![[DL基礎_近似誤差のまとめ.png]]
		1. 局所構造を持つ関数の場合
			- 一部分で滑らかさが異なる場合など
			- 前半で関数を分割→後半で表現する、というように深層構造が局所性の表現に寄与
		1. 特徴量の抽出が有効な関数の場合
			- 前半で特徴量抽出、後半で関数を表現
---
### 第12回　深層強化学習
![[DL基礎_深層強化学習の概要.png]]
深層強化学習　＝　強化学習　＋　**関数近似**(深層学習)
強化学習　＝　プランニング　＋　サンプル近似

＊講義はプランニングが主

##### 強化学習で扱う問題
- **逐次意思決定問題**
	- 分類や回帰のような即時的な意思決定ではなく、
		与えられた状況に対して、**長期的に**得をする行動を決定したい
	- 問題設定
		- エージェントが
		- 何らかの環境で
		- 意思決定を繰り返す
	- 目標
		- 最適な意思決定のルールを見つける
- 現実の逐次意思決定問題は複雑
	- すべてを含有する一般的な定式化は困難
	- **マルコフ決定過程**という数理モデルで、シンプルに定式化
##### マルコフ決定過程
- マルコフ過程
	- 未来の状態は過去には依存せず、現在の状態と遷移確率に依存するというアルゴリズム
- マルコフ決定過程
	- マルコフ過程モデルに、「行動」の概念を加えたもの
	- ある状態で何らかの行動をとったとき、
	確率的に別の状態に遷移するアルゴリズム
	![[DL基礎_マルコフ決定過程の基礎.jpg]]
	![[DL基礎_マルコフ決定過程の定義.png]]
	- 今回は複数あるマルコフ決定過程のうち、テーブルマルコフ決定過程を扱う
- テーブルマルコフ決定過程
	- 行動集合$A$と状態集合$S$が有限な、マルコフ決定過程
	- 遷移確率$P$・報酬関数$r$・方策$\pi$　すべて行列で表現可能

ここまでで、逐次意思決定の定式化ができた。
次**「どんな方策が最適か」**

##### 収益と最適方策
- 逐次意思決定のゴール
	- 長期的な累積報酬の和が最大になる方策＝最適方策
	- これをどう見つけるか
- 「長期」の長さ
	- 考慮する意思決定の長さが、有限 or 無限
	- 有限マルコフ決定過程：制限時間のあるゲーム
	- 無限マルコフ決定過程：マインクラフト
- 有限マルコフ決定過程
	- エピソード：意思決定の繰り返しの、始まりから終わり
	- ホライゾン：1エピソードに何回意思決定するか
	- エピソードの収益：1エピソードで得た報酬の合計
	- 期待収益：収益の期待値
	- 最適方策：期待収益を最大化する方策
- 無限マルコフ決定過程
	- 期待収益を有限の値にする必要性
		- 同じ期待収益の定義だと、無限大になる場合があり、方策の比較に支障が出る
	- 割引率の導入
		- $0<\gamma<1$
		- 割引収益
			- 将来の収益ほど、距離に応じて割り引く
			- $R=r^{(0)}+\gamma r^{(1)}+\gamma^2 r^{(2)}+...=\sum^\infty_{h=0} {\gamma^h r^{(h)}}$
		- 期待割引収益
			- $E^\pi [R]\leq \frac{報酬の最大値}{1-\gamma}$　より、有限
		- 最適方策
			- 期待割引収益を最大化する方策
- 最適方策の求め方
	- 今回は以下の問題設定
		- テーブルマルコフ決定過程
		- プランニング問題 $P, r$所与で$\pi^*$求める
		- 無限マルコフ決定過程
	- 求め方
		- 基本の**価値反復法**を扱う
			- 多くの深層強化学習アルゴリズム(DQN, etc.)は、これの拡張
			- マルコフ決定過程の帰納的な性質を利用して最適方策を求めるプランニングアルゴリズム（部分問題への分割、動的計画法）
		- **強化学習アルゴリズムではない**
			- あくまでプランニングアルゴリズム
	- 価値反復法
		- 方策$\pi$の状態行動価値関数 $Q^\pi \in \mathbb{R}^{S \times A}$ ←２次元行列
			- $Q^\pi(s, a)=E^\pi[R\ |\ s^{(0)}=s, a^{(0)}=a]$
			- 要するに、$Q^\pi(s, a)$とは
			「状態$s$、行動$a$から方策$\pi$で無限ステップ逐次意思決定したときに期待される割引収益」
			- $Q$関数とも
		- $\pi ^*$の価値関数$Q^{\pi^*}$が発見 = $\pi^*$も発見
			- 原理は省略
		- $Q^{\pi^*}$の見つけ方
			- $Q^{\pi^*}$は次のベルマン方程式を満たす
				- ベルマン方程式
			- 要は、ベルマン方程式を満たす$Q$が見つかれば、
			  それは必ず$Q^{\pi^*}$！
		- ベルマン誤差
			- ベルマン方程式を少し変形してベルマン誤差を定義
			- ベルマン誤差が0となる$Q$が$Q^{\pi^*}$
			- 価値反復法やDQNはベルマン誤差が小さくなるよう$Q$関数を更新する
##### 強化学習
- 価値反復法はプランニング問題($P, r$既知)で最適方策を求める方法
	- 特にベルマン方程式の2項目は、$P$既知かつ状態空間サイズ有限を前提
	- 現実的に、$P, r$は未知な場合が多い
- どう最適方策を求めるか
	- $P, r$ 未知 ＝ 強化学習
	- 状態空間サイズ無限 ＝ 深層強化学習
- 強化学習
	- $Q$学習アルゴリズム
	- $P(･|s, a$) をサンプリング
	- そのサンプルで価値反復法を近似できるのでは？
		- ベルマン方程式の2項目 $\sum_{s'\in S} P(s'|s, a) max_{a'\in A} Q(s', a')$ は期待値の形になっている
		- これをサンプルを使ってモンテカルロサンプル近似
		- こうして少しずつ$Q$関数の行列を更新
	- 学習で全パターン経験する必要
		- $Q^{\pi^*}$へ収束する条件：
			- すべての状態行動$S \times A$をカバー　かつ　学習率$\alpha$が十分小さい
	- サンプルの集め方が重要
		- 単にランダムに意思決定するとクソ効率悪そう
		- 特定の条件下では実質無限回の試行が必要
		- すべての状態行動を効率よく訪問できる行動の選択方法 ＝ 探索問題
			- 探索の話は時間足りん、詳しい話は省略
			- バンディット問題とか、、
		- ただのランダムよりマシな行動選択
			- $\epsilon-$貪欲方策
##### 深層強化学習
- 状態空間サイズが無限ならどうするか
- $Q$関数をニューラルネットワークで表現しよう
	- 「状態(画像など)を受け取り,行動空間上の値を返すネットワーク$Q_\theta : S → \mathbb{R}^A$」を使って$Q$関数を表現
- Deep Q-Network (DQN)
	- ベルマン誤差を小さくするようネットワークを更新
- DQNアルゴリズムの工夫
	- 飛ばす
##### その他
- 方策勾配法 
- REINFORCEアルゴリズム
- 期待ベルマン方程式
- アクター・クリティック法
- モデルフリーとモデルベース
- オフライン強化学習
飛ばす

### 第13回 世界モデル
親知らず抜いた直後でコンディション悪
まとめるのは諦めた。すまん。

p23にサーベイ論文

生成モデルと関わりあるのでまず復習から
- 深層生成モデル
	- 手元にあるデータをサンプリング(生成)可能な確率モデル
	- 重要な概念：推論
		- 観測変数が与えられた下で、任意の潜在変数の分布を求める
		- 結果から原因を探る作業
- 世界モデル
- 様々な世界モデル
- 世界モデルに関する研究
- 人工知能と世界モデル


世界モデルの利点は、実世界の観測から世界の表現を獲得できることにある。限られた情報から外界をモデル化することで、世界を構造的に理解し、新たな観測に対して推論を行うことができる。


--- 
[[#第2回 機械学習基礎]]
[[#第3回 ニューラルネットワーク基礎]]
[[#第4回 ニューラルネットワークの最適化・正則化]]
[[#第5回 CNNと画像処理]]
[[#第6回 RNN]]
[[#第7回 自然言語処理]]
[[#第8回 説明可能性 及び グラフニューラルネットワーク]]
[[#第10回 深層学習の理論]]
[[#第12回 深層強化学習]]
[[#第13回 世界モデル]]