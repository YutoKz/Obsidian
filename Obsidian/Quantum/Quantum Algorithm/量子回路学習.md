### 読みたい
- Quantum Circuit Learning
	- [arXiv](https://arxiv.org/abs/1803.00745)

- 

### 読んだ
- Layered Architecture for Quantum Computing 
	- 2024/03/31
	- [GoogleDrive](https://drive.google.com/file/d/1Of8XyFItiDAAfOfdq6MS4VLQlGOxLe3X/view?usp=drive_link)
	- 5層アーキテクチャ
	- 古典計算機と同様、カプセル化を採用
	- シリコン方式かつ誤り耐性の実機を意識
- Image segmentation on a quantum computer
	- 2024/04/06
	- [GoogleDrive](https://drive.google.com/file/d/1PC4L7Oii3KphdWYmdAnWvckWwJfdU6Oz/view?usp=drive_link)
	- threshold-based segmentation with Quantum Computer
		- demonstrates by producing a two-level gray image 
	- Advantage over classical: significant speedup 
	- include the current state of "Quantum image processing"
		- "how to represent image in qc"
		- "how to difinite fundamental processing operations"
	- how to represent image
		- m+2n qubits
			- m: pixel value    e.g. 256 => 8qubits
			- n: position    e.g. 1024x1024 => 10+10qubits
	- What is Oracle?
	- doesn't include how to determine the optimal threshold?
	- 要は、Quantum Oracleを使って効率的に2値化する手法の提案

#### [Interpretable Quantum Advantage in Neural Sequence Learning](https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.4.020338)
	量子機械学習 + LLM
###### どんなもの？
- quantum neural networksの持つ**表現力の高さ**と**特定のデータに対する古典neural networkへの優位性**を主張
- 量子文脈性をneural sequence learningに適用
###### 背景/モチベ
- 昨今量子プロセッサの性能向上、量子機械学習に期待
- 著者「quantum neural networkの表現力に関する直感的な理解が不足、これを古典モデルとの表現力比較により解決したい」
###### 先行研究からの改善
- 先行研究
	- 潜在的な量子モデルの表現力の優位性を示唆
- 本論文
	- これを明確化、より分かりやすく実証
	- 特に、これまで未解明であった量子/古典モデルの記憶力と表現力の違いについて取り組む
###### 技術・手法の詳細
- Contextual Recurrent Neural Network (CRNN)
	- 量子機械学習特有のモデルクラス
	- 量子文脈性を利用し、古典以上の表現力と記憶効率
	- ガウス演算と非ガウス測定を組み合わせたRNN
		- 特定の同じ分布を表現するのに必要な量子モードの数が、古典モデルが必要とする潜在空間の次元数より非常に少なく済む
		- ガウス演算：
			- 量子状態に対して行われる変換。ガウス状態（正規分布に従う量子状態）をガウス状態に変換するもの
		- 非ガウス測定：
			- ガウス状態以上の情報を抽出可能な量子測定。位相推定やパリティ測定がこれにあたる。標準的なガウス測定は位置や運動量の測定。こうしたガウス測定では得られない、量子状態の特定の特性を探るため使用。量子状態の非局所的な特性やエンタングルメントを評価するのに用いられる。
	- モデルの流れ
		- ガウス演算で量子状態を逐次的に変換
		- 非ガウス測定で重要な情報を抽出
	- 目的
		- 量子状態の持つ複雑な情報を効率的に扱いたい
		- 量子文脈性を利用することで、古典モデルでは難しい高度な関連性やパターンの解析が可能に
###### 有効性の検証方法
- CRNNの性能を検証
	- スペイン語-英語の翻訳タスクを数値実験
	- 古典的なGRU, transformerを凌駕したと主張
		- 言語をはじめとする系列データにおける、量子モデルの優位性を実証
###### 議論
- 量子文脈性が機械学習モデルの性能向上に重要
	- 複雑なデータの関連性を効率的に扱えるようになる
	- 特に、言語翻訳といった"文脈"が重要となるタスクで効果を発揮する
###### 重要視している先行研究
